path_to_storage: "src/experiments/results"

analysis_type: "swapped_layers_redundancy_analysis"

version: "0"

# model_id: "mistralai/Mistral-7B-v0.3" # model_id: "bert-base-uncased"
model_id: "EleutherAI/gpt-neo-1.3B"
quantization: null
dtype: "float32"

tokenizer_id: "EleutherAI/gpt-neo-1.3B"

benchmark_ids:
    - "truthfulqa_mc1"
evaluation_args:
    truthfulqa_mc1:
        batch_size: 8
    arc_challenge:
        batch_size: 8

targets:
    - ["layer_index", "mlp", "c_fc"]
    - ["layer_index", "mlp", "c_proj"]

num_layers: 24

figure_size: [30, 30]

verbose: 1
device: "cuda"
seed: 42
