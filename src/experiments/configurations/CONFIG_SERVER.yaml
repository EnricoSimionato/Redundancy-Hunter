########################################    General configuration parameters    ########################################
path_to_storage: "src/experiments/results"

experiment_type: "original_layer_rank_analysis"

version: 0

#just_plot: True

verbose: 1
device: "cpu"
seed: 42

########################################     Model configuration parameters     ########################################
model_id: "mistralai/Mistral-7B-v0.3"
#model_id: "meta-llama/Llama-3.1-8B"
dtype: "float16"

########################################   Tokenizer configuration parameters   ########################################
#tokenizer_id: "meta-llama/Llama-3.1-8B"
tokenizer_id: "mistralai/Mistral-7B-v0.3"

########################################       Analysis target parameters       ########################################
targets:
    - ["gate_proj"]
    - ["up_proj"]
    - ["down_proj"]

    - ["q_proj"]
    - ["k_proj"]
    - ["v_proj"]
    - ["o_proj"]

########################################        Visualization parameters        ########################################
figure_size: [40, 40]

########################################             Ranks analysis             ########################################
singular_values_threshold: 0.
explained_variance_threshold: 0.90
relative_rank: True
